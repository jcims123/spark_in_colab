{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQW8znd/ioHfmIk4l6+N3D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcims123/spark_in_colab/blob/main/20250802_spark_colab_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I7vzWGvg-O7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fee25ba-4088-4b0b-a33a-dd516c89ca7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: findspark in /usr/local/lib/python3.11/dist-packages (2.0.1)\n",
            "âœ… PySpark 3.5.0 installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# ===== CORRECTED PYSPARK SETUP FOR GOOGLE COLAB =====\n",
        "\n",
        "# Step 1: Install Java (required for Spark)\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Step 2: Download Apache Spark 3.5.0 (stable version that works reliably)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "\n",
        "# Step 3: Install findspark\n",
        "!pip install findspark\n",
        "\n",
        "# Step 4: Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "\n",
        "# Step 5: Initialize Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "print(\"âœ… PySpark 3.5.0 installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "# Create optimized Spark session for interviews\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"InterviewPrep\") \\\n",
        "    .config(\"spark.driver.memory\", \"8g\") \\\n",
        "    .config(\"spark.driver.maxResultSize\", \"2g\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
        "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(f\"âœ… Spark {spark.version} session created!\")\n",
        "print(f\"ðŸ”§ Using {spark.sparkContext.defaultParallelism} cores\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMa4MfbG__jx",
        "outputId": "12985224-4b82-4430-955f-8468df029fba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Spark 3.5.0 session created!\n",
            "ðŸ”§ Using 2 cores\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data for interviews\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
        "\n",
        "# Create sample employee data\n",
        "employees_data = [\n",
        "    (1, \"John\", \"Engineering\", 75000, \"2020-01-15\"),\n",
        "    (2, \"Alice\", \"Marketing\", 65000, \"2019-03-20\"),\n",
        "    (3, \"Bob\", \"Engineering\", 80000, \"2021-06-10\"),\n",
        "    (4, \"Carol\", \"Sales\", 70000, \"2020-11-05\"),\n",
        "    (5, \"David\", \"Engineering\", 85000, \"2018-08-12\")\n",
        "]\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"id\", IntegerType(), True),\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"department\", StringType(), True),\n",
        "    StructField(\"salary\", IntegerType(), True),\n",
        "    StructField(\"hire_date\", StringType(), True)\n",
        "])\n",
        "\n",
        "df = spark.createDataFrame(employees_data, schema)\n",
        "df.show()\n",
        "df.printSchema()\n",
        "\n",
        "# Common interview operations\n",
        "print(f\"Total employees: {df.count()}\")\n",
        "print(f\"Columns: {df.columns}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5joU22P_A8xR",
        "outputId": "bad38441-9800-4399-9c46-dcdd795c1583"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+-----------+------+----------+\n",
            "| id| name| department|salary| hire_date|\n",
            "+---+-----+-----------+------+----------+\n",
            "|  1| John|Engineering| 75000|2020-01-15|\n",
            "|  2|Alice|  Marketing| 65000|2019-03-20|\n",
            "|  3|  Bob|Engineering| 80000|2021-06-10|\n",
            "|  4|Carol|      Sales| 70000|2020-11-05|\n",
            "|  5|David|Engineering| 85000|2018-08-12|\n",
            "+---+-----+-----------+------+----------+\n",
            "\n",
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            " |-- hire_date: string (nullable = true)\n",
            "\n",
            "Total employees: 5\n",
            "Columns: ['id', 'name', 'department', 'salary', 'hire_date']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hf6itw5zBQCs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}